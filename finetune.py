"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ TrOCR –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–ø–∫–∏ FineTuning

–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: 4xP100 16GB NVLink, CPU E5-2660v3, RAM 64GB

–î–ª—è –∑–∞–ø—É—Å–∫–∞ –Ω–∞ multi-GPU –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–¥–∏–Ω –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤:

1. –° torchrun (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):
   torchrun --nproc_per_node=4 finetune.py --gpu [–¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã]

2. –° accelerate:
   accelerate config  # –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –æ–¥–∏–Ω —Ä–∞–∑
   accelerate launch finetune.py --gpu [–¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã]

3. –ù–∞ –æ–¥–Ω–æ–π GPU:
   python finetune.py --gpu [–¥—Ä—É–≥–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã]

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è 4xP100:
- batch_size=12 (–Ω–∞ GPU)
- gradient_accumulation_steps=2
- learning_rate –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è (5e-5 * –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU)
- dataloader_num_workers=8 (–¥–ª—è E5-2660v3)
- fp16 –≤–∫–ª—é—á–µ–Ω –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
"""
import os
import argparse
import torch
from torch.utils.data import DataLoader
from transformers import (
    TrOCRProcessor,
    VisionEncoderDecoderModel,
    Seq2SeqTrainingArguments,
    Seq2SeqTrainer,
    default_data_collator
)
from finetuning_dataset import FineTuningDataset
from config import Config
import json


def compute_metrics(eval_pred, processor):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
    import numpy as np
    from jiwer import wer, cer
    
    predictions, labels = eval_pred
    
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    decoded_preds = processor.batch_decode(predictions, skip_special_tokens=True)
    
    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –º–µ—Ç–∫–∏ (–∑–∞–º–µ–Ω—è–µ–º -100 –Ω–∞ pad_token_id)
    labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)
    decoded_labels = processor.batch_decode(labels, skip_special_tokens=True)
    
    # –í—ã—á–∏—Å–ª—è–µ–º WER (Word Error Rate) –∏ CER (Character Error Rate)
    wer_score = wer(decoded_labels, decoded_preds)
    cer_score = cer(decoded_labels, decoded_preds)
    
    return {
        "wer": wer_score,
        "cer": cer_score
    }


def main():
    parser = argparse.ArgumentParser(
        description="–î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ TrOCR –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–∞–ø–∫–∏ FineTuning"
    )
    parser.add_argument("--base-model", type=str, default=None,
                       help="–ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ config.py)")
    parser.add_argument("--output-dir", type=str, default="fine_tuned_model",
                       help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
    parser.add_argument("--batch-size", type=int, default=12,
                       help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 12 –¥–ª—è P100)")
    parser.add_argument("--gradient-accumulation-steps", type=int, default=2,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 2 –¥–ª—è multi-GPU)")
    parser.add_argument("--learning-rate", type=float, default=None,
                       help="–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5e-5 * –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU)")
    parser.add_argument("--num-epochs", type=int, default=10,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö")
    parser.add_argument("--warmup-steps", type=int, default=500,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –¥–ª—è warmup (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 500 –¥–ª—è multi-GPU)")
    parser.add_argument("--max-length", type=int, default=128,
                       help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    parser.add_argument("--dataloader-num-workers", type=int, default=8,
                       help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 8 –¥–ª—è E5-2660v3)")
    parser.add_argument("--save-steps", type=int, default=500,
                       help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤")
    parser.add_argument("--eval-steps", type=int, default=500,
                       help="–í—ã–ø–æ–ª–Ω—è—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤")
    parser.add_argument("--logging-steps", type=int, default=50,
                       help="–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤")
    parser.add_argument("--gpu", action="store_true",
                       help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)")
    parser.add_argument("--fine-tuning-dir", type=str, default="FineTuning",
                       help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ FineTuning")
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU
    device = "cuda" if args.gpu and torch.cuda.is_available() else "cpu"
    num_gpus = torch.cuda.device_count() if device == "cuda" else 0
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω –ª–∏ —Å–∫—Ä–∏–ø—Ç —á–µ—Ä–µ–∑ torchrun/accelerate –¥–ª—è multi-GPU
    is_distributed = os.environ.get("RANK") is not None or os.environ.get("LOCAL_RANK") is not None
    
    print(f"\n{'='*60}")
    print(f"üîß –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–ò–°–¢–ï–ú–´")
    print(f"{'='*60}")
    print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
    
    if device == "cpu":
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –û–±—É—á–µ–Ω–∏–µ –Ω–∞ CPU –æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ–µ! –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --gpu –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è.")
    else:
        print(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ GPU: {num_gpus}")
        for i in range(num_gpus):
            gpu_name = torch.cuda.get_device_name(i)
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} ({gpu_memory:.2f} GB)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º NVLink (–¥–ª—è P100 —ç—Ç–æ –≤–∞–∂–Ω–æ)
        if num_gpus > 1:
            if not is_distributed:
                print(f"\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {num_gpus} GPU, –Ω–æ —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω –Ω–µ —á–µ—Ä–µ–∑ torchrun/accelerate!")
                print(f"   –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö GPU –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
                print(f"   torchrun --nproc_per_node={num_gpus} finetune.py --gpu [–ø–∞—Ä–∞–º–µ—Ç—Ä—ã]")
                print(f"   –∏–ª–∏")
                print(f"   accelerate launch finetune.py --gpu [–ø–∞—Ä–∞–º–µ—Ç—Ä—ã]")
                print(f"   –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ GPU 0")
                num_gpus = 1  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω GPU
            else:
                print(f"\nüì° Multi-GPU —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
                print(f"   Trainer –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DistributedDataParallel")
                if torch.cuda.is_available():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ NVLink (–∫–æ—Å–≤–µ–Ω–Ω–æ —á–µ—Ä–µ–∑ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å peer access)
                    try:
                        can_access = torch.cuda.can_device_access_peer(0, 1) if num_gpus > 1 else False
                        if can_access:
                            print(f"   ‚úÖ Peer-to-peer –¥–æ—Å—Ç—É–ø –º–µ–∂–¥—É GPU –¥–æ—Å—Ç—É–ø–µ–Ω (NVLink)")
                        else:
                            print(f"   ‚ö†Ô∏è  Peer-to-peer –¥–æ—Å—Ç—É–ø –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç NVLink)")
                    except:
                        print(f"   ‚ÑπÔ∏è  NVLink —Å—Ç–∞—Ç—É—Å: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        
        print(f"{'='*60}\n")
    
    # –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
    fine_tuning_dir = args.fine_tuning_dir
    train_dir = os.path.join(fine_tuning_dir, "train")
    test_dir = os.path.join(fine_tuning_dir, "test")
    train_tsv = os.path.join(fine_tuning_dir, "train.tsv")
    test_tsv = os.path.join(fine_tuning_dir, "test.tsv")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    if not os.path.exists(train_dir):
        print(f"–û—à–∏–±–∫–∞: –ø–∞–ø–∫–∞ {train_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    if not os.path.exists(test_dir):
        print(f"–û—à–∏–±–∫–∞: –ø–∞–ø–∫–∞ {test_dir} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return
    if not os.path.exists(train_tsv):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {train_tsv} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    if not os.path.exists(test_tsv):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª {test_tsv} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
    if args.base_model:
        model_name = args.base_model
    else:
        model_name = Config.MODEL_NAME
    
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏: {model_name}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∏ –º–æ–¥–µ–ª—å
    processor = TrOCRProcessor.from_pretrained(model_name)
    model = VisionEncoderDecoderModel.from_pretrained(model_name)
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id
    model.config.pad_token_id = processor.tokenizer.pad_token_id
    model.config.vocab_size = model.config.decoder.vocab_size
    
    # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
    # –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ Trainer —Å multi-GPU, –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
    # —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ —á–µ—Ä–µ–∑ DistributedDataParallel, –ø–æ—ç—Ç–æ–º—É –Ω–µ –Ω—É–∂–Ω–æ –≤—Ä—É—á–Ω—É—é –ø–µ—Ä–µ–º–µ—â–∞—Ç—å
    if num_gpus == 0:
        model = model.to(device)
    
    print("–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç—ã
    train_dataset = FineTuningDataset(
        images_dir=train_dir,
        tsv_file=train_tsv,
        processor=processor,
        max_length=args.max_length
    )
    
    test_dataset = FineTuningDataset(
        images_dir=test_dir,
        tsv_file=test_tsv,
        processor=processor,
        max_length=args.max_length
    )
    
    print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(train_dataset)}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(test_dataset)}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º learning rate —Å —É—á–µ—Ç–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ GPU (linear scaling rule)
    if args.learning_rate is None:
        base_lr = 5e-5
        effective_num_gpus = max(num_gpus, 1)  # –ú–∏–Ω–∏–º—É–º 1 –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
        learning_rate = base_lr * effective_num_gpus
    else:
        learning_rate = args.learning_rate
    
    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ —Å —É—á–µ—Ç–æ–º multi-GPU
    effective_batch_size = args.batch_size * args.gradient_accumulation_steps * max(num_gpus, 1)
    steps_per_epoch = len(train_dataset) // effective_batch_size
    total_steps = steps_per_epoch * args.num_epochs
    
    print(f"\nüìä –ü–ê–†–ê–ú–ï–¢–†–´ –û–ë–£–ß–ï–ù–ò–Ø:")
    print(f"{'='*60}")
    print(f"   –ë–∞—Ç—á —Ä–∞–∑–º–µ—Ä (–Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ): {args.batch_size}")
    print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU: {max(num_gpus, 1)}")
    print(f"   –ù–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞: {args.gradient_accumulation_steps}")
    print(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {effective_batch_size}")
    print(f"   Learning rate: {learning_rate:.2e} {'(–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω –¥–ª—è multi-GPU)' if num_gpus > 1 and args.learning_rate is None else ''}")
    print(f"   –≠–ø–æ—Ö: {args.num_epochs}")
    print(f"   –®–∞–≥–æ–≤ –Ω–∞ —ç–ø–æ—Ö—É: ~{steps_per_epoch}")
    print(f"   –í—Å–µ–≥–æ —à–∞–≥–æ–≤: ~{total_steps}")
    print(f"   Warmup steps: {args.warmup_steps}")
    print(f"   –í–æ—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {args.dataloader_num_workers if device == 'cuda' else 0}")
    print(f"   Mixed Precision (FP16): {'–î–∞' if torch.cuda.is_available() else '–ù–µ—Ç'}")
    print(f"{'='*60}\n")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–ª—è 4xP100 16GB NVLink
    training_args = Seq2SeqTrainingArguments(
        output_dir=args.output_dir,
        per_device_train_batch_size=args.batch_size,
        per_device_eval_batch_size=args.batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=learning_rate,
        num_train_epochs=args.num_epochs,
        warmup_steps=args.warmup_steps,
        logging_steps=args.logging_steps,
        save_steps=args.save_steps,
        eval_steps=args.eval_steps,
        eval_strategy="steps",
        save_strategy="steps",
        load_best_model_at_end=True,
        metric_for_best_model="wer",
        greater_is_better=False,
        push_to_hub=False,
        report_to="none",
        # FP16 –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏ –Ω–∞ P100 (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
        fp16=torch.cuda.is_available(),
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è multi-GPU —Å NVLink
        dataloader_num_workers=args.dataloader_num_workers if device == "cuda" else 0,
        dataloader_pin_memory=torch.cuda.is_available(),  # –£—Å–∫–æ—Ä—è–µ—Ç –ø–µ—Ä–µ–¥–∞—á—É –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU
        # –î–ª—è multi-GPU: –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç DistributedDataParallel
        ddp_find_unused_parameters=False,  # –£—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ multi-GPU
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        remove_unused_columns=False,  # –í–∞–∂–Ω–æ –¥–ª—è seq2seq –º–æ–¥–µ–ª–µ–π
        # –î–ª—è –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏ multi-GPU
        gradient_checkpointing=False,  # –ú–æ–∂–Ω–æ –≤–∫–ª—é—á–∏—Ç—å, –µ—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –ø–∞–º—è—Ç–∏
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        save_total_limit=3,  # –•—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        logging_first_step=True,
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è NVLink
        dataloader_drop_last=True,  # –ò–∑–±–µ–≥–∞–µ–º –ø—Ä–æ–±–ª–µ–º —Å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–µ–π –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º –±–∞—Ç—á–µ
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —Å –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º
    def compute_metrics_with_processor(eval_pred):
        return compute_metrics(eval_pred, processor)
    
    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=test_dataset,
        data_collator=default_data_collator,
        compute_metrics=compute_metrics_with_processor,
    )
    
    print("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    if num_gpus > 1:
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {num_gpus} GPU")
        print(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {effective_batch_size}")
    print()
    
    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
    train_result = trainer.train()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    print(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ {args.output_dir}...")
    trainer.save_model()
    processor.save_pretrained(args.output_dir)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = train_result.metrics
    metrics_file = os.path.join(args.output_dir, "training_metrics.json")
    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    
    print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {args.output_dir}")
    print(f"–ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {metrics_file}")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ—Ü–µ–Ω–∫—É
    print("\n–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    eval_metrics = trainer.evaluate()
    print(f"–§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
    print(f"  WER (Word Error Rate): {eval_metrics.get('eval_wer', 'N/A'):.4f}")
    print(f"  CER (Character Error Rate): {eval_metrics.get('eval_cer', 'N/A'):.4f}")


if __name__ == "__main__":
    main()

